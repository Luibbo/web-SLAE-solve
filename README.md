# Solve Complex Task

Сервіс для виконання складних обчислювальних задач у фоновому режимі з моніторингом у реальному часі.

---

## Про сервіс

**Solve Complex Task** — це веб-платформа, розроблена для вирішення проблеми блокування інтерфейсу під час виконання важких математичних операцій.

Сервіс дозволяє користувачам створювати ресурсоємні задачі (наприклад, розв'язання систем лінійних рівнянь великої розмірності), які делегуються на виконання у фонові процеси.

**Ключові можливості:**
* **Асинхронність:** Важкі обчислення не впливають на чуйність веб-інтерфейсу.
* **Real-time прогрес:** Користувач бачить відсоток виконання та прогнозований час завершення завдяки WebSocket з'єднанню.
* **Безпека:** Реєстрація та авторизація через JWT токени.
* **Історія:** Збереження всіх задач, їх параметрів та результатів.

---

## Технологічний стек

Проект побудований на сучасному стеку Python з використанням мікросервісних патернів.

* **Мова:** Python 3.11+
* **API Framework:** FastAPI (Async)
* **Background Tasks:** Celery
* **Broker & Cache:** Redis
* **Database:** PostgreSQL
* **Containerization:** Docker, Docker Compose
* **Web Server:** Nginx

**Ключові особливості реалізації:**
* Load Balancing (балансування навантаження між інстансами API).
* Dedicated Workers (окремі контейнери для обчислень).
* Database Migrations (Alembic).
* SSL Encryption (HTTPS).

---

## Архітектура

Система спроектована для забезпечення масштабованості та відмовостійкості:

* **FastAPI1 та FastAPI2:** Два ідентичні контейнери з основним додатком. Це реалізація горизонтального масштабування (horizontal scaling) для обробки більшої кількості HTTP-запитів.
* **Nginx:** Виконує роль Reverse Proxy та Load Balancer'а. Приймає вхідний трафік, забезпечує SSL-термінацію та розподіляє запити між `FastAPI1` та `FastAPI2`.
* **Redis:**
    * Брокер повідомлень для Celery (черга задач).
    * Pub/Sub механізм для передачі статусів виконання задач у WebSocket-канали в реальному часі.
* **PostgreSQL:** Реляційна база даних для зберігання користувачів та метаданих задач.
* **Worker:** Окремий контейнер із Celery, який займається виключно "пережовуванням" важких математичних задач, не навантажуючи основні API-сервіси.
* **PgAdmin:** Веб-інтерфейс для адміністрування бази даних.
* **Docker Compose:** Оркестратор, що піднімає та зв'язує всі сервіси в єдину мережу.

---

## Технічні рішення та пояснення

Чому інфраструктура налаштована саме так:

1.  **Чому два FastAPI-контейнери?**
    Для відмовостійкості та розподілу навантаження. Якщо один контейнер впаде або буде перевантажений, Nginx перенаправить запит на інший.

2.  **Чому `RUN_MIGRATIONS` "true" лише в одному інстансі?**
    Змінна оточення `RUN_MIGRATIONS` контролює запуск міграцій бази даних (Alembic) при старті. Вона включена тільки на `fastapi1`, щоб уникнути стану гонки (race condition), коли два сервіси одночасно намагаються змінити структуру БД, що може призвести до помилок.

3.  **Чому `prefetch-multiplier=1` для воркера?**
    Це налаштування Celery змушує воркера брати зі черги рівно одну задачу за раз. Оскільки задачі важкі і тривалі (CPU-bound), нам не потрібно, щоб один воркер "бронював" собі кілька задач наперед, блокуючи їх виконання іншими потенційними воркерами.

4.  **Чому `pool=solo`?**
    Використовується пул виконання `solo`, щоб задача виконувалася в тому ж процесі без створення дочірніх процесів (forking). Це зменшує оверхед (накладні витрати) ресурсів і спрощує моніторинг для поодиноких важких обчислень.

5.  **Як працює SSL?**
    Використовуються self-signed (самопідписані) сертифікати, згенеровані локально. Nginx налаштований слухати 443 порт, шифрувати трафік і проксувати його на внутрішні HTTP-порти додатків.

---

## Запуск проекту

Щоб розгорнути проект локально:

1.  **Клонування репозиторію**
    `git clone <repo_url>`

2.  **Налаштування змінних оточення**
    Створіть файл `.env` на основі `.env.example`.

3.  **Запуск контейнерів**
    Виконайте команду для збірки та запуску:
    ```bash
    docker-compose up --build
    ```

4.  **Доступні порти**
    * Web UI / API: `https://localhost` (порт 443) або `http://localhost` (порт 80)
    * PgAdmin: `http://localhost:5050`

---

## Структура директорій

Короткий огляд організації коду:

* **`app/`**: Основна директорія з вихідним кодом Python.
    * Містить логіку API (routes), налаштування безпеки (auth), моделі даних (models/schemas) та бізнес-логіку обчислень.
* **`nginx.conf`**: Конфігураційний файл для Nginx (налаштування проксі, SSL, апстрімів).
* **`docker-compose.yml`**: Опис інфраструктури, сервісів, мереж та томів (volumes).

---

## Frontend / UI

Опис інтерфейсу користувача:

1.  **Sign Up / Login**:
    Сторінка авторизації. Користувач вводить Email та Пароль для отримання JWT токена доступу.
<img width="1900" height="912" alt="image" src="https://github.com/user-attachments/assets/5c2b8aeb-5bd1-4fb0-b693-aaffdf009c7a" />

2.  **Create Task**:
    Сторінка створення нової задачі. Користувач вказує розмір матриці ($n$), та заповнює дані (Матриця A та Вектор b) для розрахунку.
<img width="1897" height="903" alt="image" src="https://github.com/user-attachments/assets/ab12417a-cc44-455f-9769-d1a837c0eeec" />

3.  **Task Details**:
    Сторінка активної задачі. Показує прогрес виконання у відсотках, розрахунковий час до завершення, метрики складності алгоритму ($O(n^3)$) та кнопку скасування задачі. Статус оновлюється в реальному часі.
<img width="1916" height="905" alt="image" src="https://github.com/user-attachments/assets/c815fa64-0c9c-4cf7-bfdb-134d90526633" />

4.  **Task History**:
    Загальний список усіх задач користувача. Дозволяє переглянути статус кожної задачі (Completed/Running) та детальні результати обчислень для завершених задач.
<img width="1918" height="911" alt="image" src="https://github.com/user-attachments/assets/286f06e8-c448-40d7-976d-fa40dd58153a" />
